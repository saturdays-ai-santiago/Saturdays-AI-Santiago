{
  "cells": [
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## Regression con el dataset BIWI"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "Este es un ejemplo m√°s avanzado para mostrar como crear bases de datos costumizadas y hace regrecion con imagenes. La tarea es escontrar las coordenadas del centro de la cabeza en cada imagen. La data proviene del [BIWI head pose dataset](https://data.vision.ee.ethz.ch/cvl/gfanelli/head_pose/head_forest.html#db), gracias a Gabriele Fanelli et al. Aqui se convirtieron las imagen a formato jpeg, lo que hay que bajar la base de datos desde [este link](https://s3.amazonaws.com/fast-ai-imagelocal/biwi_head_pose.tgz)."
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "!mkdir ~/.fastai\n!mkdir ~/.fastai/data\n!mkdir ~/.fastai/data/biwi_head_pose\n!ln -s /data/home/instructor1/.fastai/data/biwi_head_pose/0* ~/.fastai/data/biwi_head_pose/\n!ln -s /data/home/instructor1/.fastai/data/biwi_head_pose/1* ~/.fastai/data/biwi_head_pose/\n!ln -s /data/home/instructor1/.fastai/data/biwi_head_pose/2* ~/.fastai/data/biwi_head_pose/",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%reload_ext autoreload\n%autoreload 2\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#import torch\n#torch.cuda.set_device(2)\nfrom fastai.vision import *",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## Obteniendo y convirtiendo la data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#path = untar_data(URLs.BIWI_HEAD_POSE)\npath = Config.data_path()/'biwi_head_pose'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cal = np.genfromtxt(path/'01'/'rgb.cal', skip_footer=6); cal",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "fname = '09/frame_00667_rgb.jpg'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def img2txt_name(f): return path/f'{str(f)[:-7]}pose.txt'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "code",
      "source": "img = open_image(path/fname)\nimg.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ctr = np.genfromtxt(img2txt_name(fname), skip_header=3); ctr",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "code",
      "source": "def convert_biwi(coords):\n    c1 = coords[0] * cal[0][0]/coords[2] + cal[0][2]\n    c2 = coords[1] * cal[1][1]/coords[2] + cal[1][2]\n    return tensor([c2,c1])\n\ndef get_ctr(f):\n    ctr = np.genfromtxt(img2txt_name(f), skip_header=3)\n    return convert_biwi(ctr)\n\ndef get_ip(img,pts): return ImagePoints(FlowField(img.size, pts), scale=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "get_ctr(fname)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "code",
      "source": "ctr = get_ctr(fname)\nimg.show(y=get_ip(img, ctr), figsize=(6, 6))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## Creando el dataset"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data = (PointsItemList.from_folder(path)\n        .split_by_valid_func(lambda o: o.parent.name=='13')\n        .label_from_func(get_ctr)\n        .transform(get_transforms(), tfm_y=True, size=(120,160))\n        .databunch().normalize(imagenet_stats)\n       )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "code",
      "source": "data.show_batch(3, figsize=(9,6))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## Entrenar el modelo"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn = cnn_learner(data, models.resnet34)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn.lr_find()\nlearn.recorder.plot()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "lr = 2e-2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "code",
      "source": "learn.fit_one_cycle(5, slice(lr))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn.save('stage-1')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn.load('stage-1');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "slideshow": {
          "slide_type": "subslide"
        },
        "scrolled": true
      },
      "cell_type": "code",
      "source": "learn.show_results()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## Data augmentation"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "tfms = get_transforms(max_rotate=20, max_zoom=1.5, max_lighting=0.5, max_warp=0.4, p_affine=1., p_lighting=1.)\n\ndata = (PointsItemList.from_folder(path)\n        .split_by_valid_func(lambda o: o.parent.name=='13')\n        .label_from_func(get_ctr)\n        .transform(tfms, tfm_y=True, size=(120,160))\n        .databunch().normalize(imagenet_stats)\n       )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "code",
      "source": "def _plot(i,j,ax):\n    x,y = data.train_ds[0]\n    x.show(ax, y=y)\n\nplot_multi(_plot, 3, 3, figsize=(8,6))",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "display_name": "Python 3.6 - AzureML",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "file_extension": ".py",
      "nbconvert_exporter": "python",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3"
    },
    "celltoolbar": "Slideshow"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}