{
  "cells": [
    {
      "metadata": {
        "id": "4T5oyU7UGUzZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "# Language Modeling & Sentiment Analysis of IMDB movie reviews"
    },
    {
      "metadata": {
        "id": "zT6TTtquGUzb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "We will be looking at IMDB movie reviews.  We want to determine if a review is negative or positive, based on the text.  In order to do this, we will be using **transfer learning**.\n\nTransfer learning has been widely used with great success in computer vision for several years, but only in the last year or so has it been successfully applied to NLP (beginning with ULMFit, which we will use here, which was built upon by BERT and GPT-2).\n\nAs Sebastian Ruder wrote in [The Gradient](https://thegradient.pub/) last summer, [NLP's ImageNet moment has arrived](https://thegradient.pub/nlp-imagenet/)."
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "JgpR1JfDsezq"
      },
      "cell_type": "markdown",
      "source": "# Modelado de lenguaje y análisis de opinión de comentarios de películas IMDB"
    },
    {
      "metadata": {
        "id": "GxaUkfcds9s7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Vamos a ver comentarios de películas de IMDB. Queremos determinar si una revisión es negativa o positiva, según el texto. Para hacer esto, utilizaremos el aprendizaje de transferencia.\n\nEl aprendizaje por transferencia se ha utilizado ampliamente con gran éxito en visión por computadora durante varios años, pero solo en el último año más o menos se ha aplicado con éxito a NLP (comenzando con ULMFit, que usaremos aquí, que fue desarrollado por BERT y GPT -2).\n\nComo Sebastian Ruder escribió en [The Gradient](https://thegradient.pub/) el verano pasado, [ha llegado el momento ImageNet de NLP](https://thegradient.pub/nlp-imagenet/)."
    },
    {
      "metadata": {
        "id": "W3NbRIY1GUzi",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "%reload_ext autoreload\n%autoreload 2\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UfhnL3vqGUzq",
        "colab_type": "code",
        "outputId": "549859bf-860d-4d6f-d11b-1d5b6f16a89c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "#%%bash\n#pip install fastai",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rHsK53XdGUzx",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "from fastai import *\nfrom fastai.text import *",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1IW2ZIOmGUz3",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "# import fastai.utils.collect_env\n# fastai.utils.collect_env.show_install()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nAWZ7DKtGUz9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Note that language models can use a lot of GPU, so you may need to decrease batchsize here."
    },
    {
      "metadata": {
        "id": "v9RBs8gStJnL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Ten en cuenta que los modelos de lenguaje pueden usar una gran cantidad de GPU, por lo que es posible que deba reducir el tamaño del lote (batch) aquí."
    },
    {
      "metadata": {
        "id": "VKnJxQslGUz-",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "# bs=48\nbs=24\n#bs=192",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dltZVZYbGU0I",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "#torch.cuda.set_device(0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "heading_collapsed": true,
        "id": "viBMA0g8GU0M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "## Preparing the data (on a sample)"
    },
    {
      "metadata": {
        "hidden": true,
        "id": "KP8atlVDGU0O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "First let's download the dataset we are going to study. The [dataset](http://ai.stanford.edu/~amaas/data/sentiment/) has been curated by Andrew Maas et al. and contains a total of 100,000 reviews on IMDB. 25,000 of them are labelled as positive and negative for training, another 25,000 are labelled for testing (in both cases they are highly polarized). The remaning 50,000 is an additional unlabelled data (but we will find a use for it nonetheless).\n\nWe'll begin with a sample we've prepared for you, so that things run quickly before going over the full dataset."
    },
    {
      "metadata": {
        "id": "fqVWAa-DtcX_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "## Preparación de los datos (en una muestra)"
    },
    {
      "metadata": {
        "id": "eZ2ANb5Ntj9g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "### Esta parte se encuentra comentada, ya que no será necesario bajar los datos: se usará una copia de ellos que ya se encuentra en la máquina virtual. \nPrimero descarguemos el conjunto de datos que vamos a estudiar. El [conjunto de datos](http://ai.stanford.edu/~amaas/data/sentiment/) ha sido preparado por Andrew Maas et al. y contiene un total de 100,000 comentarios en IMDB. 25,000 de ellos están etiquetados como positivos y negativos para el entrenamiento, otros 25,000 están etiquetados para pruebas (en ambos casos están altamente polarizados). Los 50,000 restantes son datos adicionales no etiquetados (pero de todos modos lo usaremos).\n\nComenzaremos con una muestra que hemos preparado para ustedes, de modo que las cosas se ejecuten rápidamente antes de revisar el conjunto de datos completo."
    },
    {
      "metadata": {
        "hidden": true,
        "id": "XQjALyZCGU0P",
        "colab_type": "code",
        "outputId": "cc93415b-dd4f-4a42-e25e-8b5b34fbd7e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "#path = untar_data(URLs.IMDB_SAMPLE)\n#path.ls()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Enlace simbolico (symlink / acceso directo) de la carpeta con los datos en la ubicacion correspondiente. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!mkdir ~/.fastai\n!mkdir ~/.fastai/data\n!mkdir ~/.fastai/data/imdb_sample\n!ln -s /data/home/admin101/.fastai/data/imdb_sample/t* ~/.fastai/data/imdb_sample/",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "path = Config.data_path()/'imdb_sample'\npath.mkdir(parents=True, exist_ok=True)\npath.ls()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "LECFL35VGU0X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "It contains one line per review, with the label ('negative' or 'positive'), the text and a flag to determine if it should be part of the validation set or the training set. If we ignore this flag, we can create a DataBunch containing this data in one line of code:"
    },
    {
      "metadata": {
        "id": "4mmvwmMTt5dw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Contiene una línea por comentario (review), con la etiqueta ('negativo' o 'positivo'), el texto y una bandera para determinar si debe ser parte del conjunto de validación o del conjunto de entrenamiento. Si ignoramos esta bandera, podemos crear un DataBunch que contenga estos datos en una línea de código:"
    },
    {
      "metadata": {
        "hidden": true,
        "id": "wJyrwJdaGU0Y",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "%timeit\ndata_lm = TextDataBunch.from_csv(path, 'texts.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "qjbu4YcRGU0e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "By executing this line a process was launched that took a bit of time. Let's dig a bit into it. Images could be fed (almost) directly into a model because they're just a big array of pixel values that are floats between 0 and 1. A text is composed of words, and we can't apply mathematical functions to them directly. We first have to convert them to numbers. This is done in two differents steps: tokenization and numericalization. A `TextDataBunch` does all of that behind the scenes for you."
    },
    {
      "metadata": {
        "id": "1YyuyCInuDkC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Al ejecutar esta línea, se lanzó un proceso que tomó un poco de tiempo. Profundicemos un poco en ello. Las imágenes se pueden alimentar (casi) directamente a un modelo porque son solo una gran variedad de valores de píxeles que flotan entre 0 y 1. Un texto está compuesto de palabras, y no podemos aplicarles funciones matemáticas directamente. Primero tenemos que convertirlos a números. Esto se realiza en dos pasos diferentes: tokenización y numeración. Un `TextDataBunch` hace todo eso detrás de escena por usted."
    },
    {
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "rMvY3sU7GU0g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "### Tokenization"
    },
    {
      "metadata": {
        "hidden": true,
        "id": "HTe7Rzc1GU0i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "The first step of processing we make texts go through is to split the raw sentences into words, or more exactly tokens. The easiest way to do this would be to split the string on spaces, but we can be smarter:\n\n- we need to take care of punctuation\n- some words are contractions of two different words, like isn't or don't\n- we may need to clean some parts of our texts, if there's HTML code for instance\n\nTo see what the tokenizer had done behind the scenes, let's have a look at a few texts in a batch."
    },
    {
      "metadata": {
        "hidden": true,
        "id": "YMQo8GOoGU0j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "The texts are truncated at 100 tokens for more readability. We can see that it did more than just split on space and punctuation symbols: \n- the \"'s\" are grouped together in one token\n- the contractions are separated like his: \"did\", \"n't\"\n- content has been cleaned for any HTML symbol and lower cased\n- there are several special tokens (all those that begin by xx), to replace unkown tokens (see below) or to introduce different text fields (here we only have one)."
    },
    {
      "metadata": {
        "id": "NfBYA4PBuVrH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "## Tokenización"
    },
    {
      "metadata": {
        "id": "oAlkEylcuaUC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "El primer paso del procesamiento por el que hacemos pasar los textos es dividir las oraciones sin procesar en palabras, o más exactamente tokens. La forma más fácil de hacer esto sería dividir la cadena en espacios, pero podemos ser más inteligentes:\n\n- tenemos que ocuparnos de la puntuación\n- algunas palabras son contracciones de dos palabras diferentes, como no es o no\n- es posible que necesitemos limpiar algunas partes de nuestros textos, si hay código HTML, por ejemplo\n\nPara ver lo que el tokenizador había hecho detrás de escena, echemos un vistazo a algunos textos en un lote."
    },
    {
      "metadata": {
        "id": "xePfemFkucH1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Los textos se truncan en 100 tokens para mayor legibilidad. Podemos ver que hizo más que solo dividir en espacio y símbolos de puntuación:\n- las \"'s\" se agrupan en una ficha\n- las contracciones se separan como la suya: \"did\", \"n't\"\n- el contenido se ha limpiado para cualquier símbolo HTML y en minúsculas\n- hay varios tokens especiales (todos aquellos que comienzan por xx), para reemplazar tokens desconocidos (ver más abajo) o para introducir diferentes campos de texto (aquí solo tenemos uno)."
    },
    {
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "3UK-4rLrGU0k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "### Numericalization"
    },
    {
      "metadata": {
        "hidden": true,
        "id": "L4RbawaeGU0m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Once we have extracted tokens from our texts, we convert to integers by creating a list of all the words used. We only keep the ones that appear at list twice with a maximum vocabulary size of 60,000 (by default) and replace the ones that don't make the cut by the unknown token `UNK`.\n\nThe correspondance from ids tokens is stored in the `vocab` attribute of our datasets, in a dictionary called `itos` (for int to string)."
    },
    {
      "metadata": {
        "hidden": true,
        "id": "eWjlm7C4GU0n",
        "colab_type": "code",
        "outputId": "6b379a29-5449-4b53-e48b-793381f64988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_lm.vocab.itos[:10]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "1en0Txf2GU0t",
        "colab_type": "code",
        "outputId": "0d6937b3-d6b3-47cd-f0f2-dc06ea5b91b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_lm.train_ds[0][0]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "S4610F8FGU0z",
        "colab_type": "code",
        "outputId": "a65071fc-4484-466b-c980-0cf94dcfd98e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_lm.train_ds[0][0].data[:10]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WDGUkE5YGU0_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "## Modelo de Lenguaje (Language model)"
    },
    {
      "metadata": {
        "id": "rze0o2uBGU1D",
        "colab_type": "code",
        "outputId": "2ff68b1b-e418-4e1a-ef1e-5fd7d89f799a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "path = untar_data(URLs.IMDB)\npath.ls()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Enlace simbolico (symlink / acceso directo) de la carpeta con los datos en la ubicacion correspondiente. "
    },
    {
      "metadata": {
        "id": "t1SSIRKyGU1K",
        "colab_type": "code",
        "outputId": "e6aea873-dc42-408a-cb50-6028cffe2f81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "#!mkdir ~/.fastai/data\n#!mkdir ~/.fastai/data/imdb\n#!ln -s /data/home/admin101/.fastai/data/imdb/t* ~/.fastai/data/imdb/\n#!ln -s /data/home/admin101/.fastai/data/imdb/u* ~/.fastai/data/imdb/",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#path = Config.data_path()/'imdb'\n#path.mkdir(parents=True, exist_ok=True)\n#path.ls()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#(path/'train').ls()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KfWCA_-gGU1R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "The reviews are in a training and test set following an imagenet structure. The only difference is that there is an `unsup` folder in `train` that contains the unlabelled data.\n\nWe're not going to train a model that classifies the reviews from scratch. Like in computer vision, we'll use a model pretrained on a bigger dataset (a cleaned subset of wikipeia called [wikitext-103](https://einstein.ai/research/blog/the-wikitext-long-term-dependency-language-modeling-dataset)). That model has been trained to guess what the next word, its input being all the previous words. It has a recurrent structure and a hidden state that is updated each time it sees a new word. This hidden state thus contains information about the sentence up to that point.\n\nWe are going to use that 'knowledge' of the English language to build our classifier, but first, like for computer vision, we need to fine-tune the pretrained model to our particular dataset. Because the English of the reviews left by people on IMDB isn't the same as the English of wikipedia, we'll need to adjust a little bit the parameters of our model. Plus there might be some words extremely common in that dataset that were barely present in wikipedia, and therefore might no be part of the vocabulary the model was trained on."
    },
    {
      "metadata": {
        "id": "oePW2uGmwVA6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Los comentarios están en un conjunto de entrenamiento y prueba siguiendo una estructura imagenet. La única diferencia es que hay una carpeta `unsup` en` train` que contiene los datos no etiquetados.\n\nNo vamos a entrenar un modelo que clasifique los comentarios desde cero. Al igual que en visión por computadora, utilizaremos un modelo pre-entrenado en un conjunto de datos más grande (un subconjunto limpio de wikipeia llamado [wikitext-103](https://einstein.ai/research/blog/the-wikitext-long-term-dependency -language-modeling-dataset)). Ese modelo ha sido entrenado para adivinar cuál es la siguiente palabra, siendo su entrada todas las palabras anteriores. Tiene una estructura recurrente y un estado oculto que se actualiza cada vez que ve una nueva palabra. Este estado oculto contiene información sobre la oración hasta ese punto.\n\nVamos a utilizar ese 'conocimiento' del idioma inglés para construir nuestro clasificador, pero primero, como en el caso de la visión por computadora, necesitamos ajustar el modelo previamente entrenado a nuestro conjunto de datos en particular. Debido a que el inglés de las reseñas dejadas por las personas en IMDB no es el mismo que el inglés de wikipedia, necesitaremos ajustar un poco los parámetros de nuestro modelo. Además, puede haber algunas palabras extremadamente comunes en ese conjunto de datos que apenas estaban presentes en wikipedia y, por lo tanto, podrían no ser parte del vocabulario en el que se entrenó el modelo."
    },
    {
      "metadata": {
        "heading_collapsed": true,
        "id": "_IzbglG6GU1Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "### Creating the TextLMDataBunch"
    },
    {
      "metadata": {
        "hidden": true,
        "id": "mLE4jGrgGU1Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "This is where the unlabelled data is going to be useful to us, as we can use it to fine-tune our model. Let's create our data object with the data block API (next line takes a few minutes)."
    },
    {
      "metadata": {
        "id": "GkmQpfejw08A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "### Crear el TextLMDataBunch"
    },
    {
      "metadata": {
        "id": "C83_AJwsxA40",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Aquí es donde los datos no etiquetados nos serán útiles, ya que podemos usarlos para ajustar nuestro modelo. Creemos nuestro objeto de datos con la API de bloque de datos (la siguiente línea lleva unos minutos)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "path.ls()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "Ss1OWH82GU1f",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_lm = (TextList.from_folder(path)\n           #Inputs: all the text files in path\n            .filter_by_folder(include=['train', 'test', 'unsup']) \n           #We may have other temp folders that contain text files so we only keep what's in train and test\n            .split_by_rand_pct(0.1, seed=42)\n           #We randomly split and keep 10% (10,000 reviews) for validation\n            .label_for_lm()           \n           #We want to do a language model so we label accordingly\n            .databunch(bs=bs, num_workers=1))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_lm.train_ds",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "3MtGdPkNGU1j",
        "colab_type": "code",
        "outputId": "aa87120a-baf4-4423-bd6f-417b53d8b990",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "len(data_lm.vocab.itos),len(data_lm.train_ds)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_lm",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "kWDFeq-UGU1n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "We have to use a special kind of `TextDataBunch` for the language model, that ignores the labels (that's why we put 0 everywhere), will shuffle the texts at each epoch before concatenating them all together (only for training, we don't shuffle for the validation set) and will send batches that read that text in order with targets that are the next word in the sentence.\n\nThe line before being a bit long, we want to load quickly the final ids by using the following cell."
    },
    {
      "metadata": {
        "id": "wn9prWDnxUAk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Tenemos que usar un tipo especial de `TextDataBunch` para el modelo de lenguaje, que ignora las etiquetas (es por eso que ponemos 0 en todas partes), mezclará los textos en cada época antes de concatenarlos todos juntos (solo para entrenamiento, no lo hacemos), (mezcla aleatoria para el conjunto de validación) y enviará lotes que leen ese texto en orden con los objetivos que son la siguiente palabra en la oración.\n\nLa línea antes de ser un poco larga, queremos cargar rápidamente los identificadores finales utilizando la siguiente celda."
    },
    {
      "metadata": {
        "hidden": true,
        "id": "GEsLDlBfGU1o",
        "colab_type": "code",
        "outputId": "c9eb62d7-9918-4980-8b7b-04eaca876969",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_lm.show_batch()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "mT8gmG4jGU1s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Let's save our databunch for next time:"
    },
    {
      "metadata": {
        "id": "fHFNvsFcxgOG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Guardemos nuestros datos para la próxima vez:"
    },
    {
      "metadata": {
        "hidden": true,
        "id": "T0h9PAVOGU1t",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_lm.save('lm_databunch')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NjACod38GU1x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "### Loading saved data, and creating the language model"
    },
    {
      "metadata": {
        "id": "p5fYoV3Px3ns",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "### Cargando datos guardados y creando el modelo de lenguaje"
    },
    {
      "metadata": {
        "id": "LuAVJ8ZXGU10",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_lm = load_data(path, 'lm_databunch', bs=bs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FaIqsTM3GU19",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "We can then put this in a learner object very easily with a model loaded with the pretrained weights. They'll be downloaded the first time you'll execute the following line and stored in `~/.fastai/models/` (or elsewhere if you specified different paths in your config file)."
    },
    {
      "metadata": {
        "id": "YH2sKAUpyBEq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Entonces podemos poner esto en un objeto de aprendizaje muy fácilmente con un modelo cargado con los pesos preentrenados. Se descargarán la primera vez que ejecute la siguiente línea y se almacenarán en `~ / .fastai / models /` (o en otro lugar si especificó diferentes rutas en su archivo de configuración)."
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "zM5BWmNoGU1-",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_lm = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w7kT4Hl6GU2C",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "#wiki_itos = pickle.load(open(Config().model_path()/'wt103-1/itos_wt103.pkl', 'rb')) # dependiendo de la máquina en que se ejecuta \nwiki_itos = pickle.load(open(Config().model_path()/'wt103-fwd/itos_wt103.pkl', 'rb'))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pDGqQFwL0t8V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Sitienes un error en el pickle.load ejecuta el bash ajunto"
    },
    {
      "metadata": {
        "id": "pwuNcvMDyy1a",
        "colab_type": "code",
        "outputId": "80069fb6-7e3a-4abd-dba7-6376af64c5be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "#%%bash\n#jupyter notebook --NotebookApp.iopub_data_rate_limit=1e10\n#curl -O http://files.fast.ai/models/wt103/itos_wt103.pkl\n#mkdir ../root/.fastai/models/wt103-1\n#mv itos_wt103.pkl ../root/.fastai/models/wt103-1/itos_wt103.pkl\n#ls /root/.fastai/models/wt103-1 -A",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wLYyXf3rGU2G",
        "colab_type": "code",
        "outputId": "861786ca-9aee-4614-ae26-74fc0d418b63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "wiki_itos[:10]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cwKoy64oGU2K",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "vocab = data_lm.vocab",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZzuanmoZGU2N",
        "colab_type": "code",
        "outputId": "7d973c90-5a00-41c9-e560-ab791deef110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "vocab.stoi[\"stingray\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m3tmMss4GU2T",
        "colab_type": "code",
        "outputId": "e3a13051-6a27-4fe4-a90c-581154df3f6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "vocab.itos[vocab.stoi[\"stingray\"]]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n8hbCpeMGU2W",
        "colab_type": "code",
        "outputId": "b648b5da-213d-4796-8bc3-157752527a41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "vocab.itos[vocab.stoi[\"mobula\"]]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8hWUA71XGU2c",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "awd = learn_lm.model[0]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IvF8AIrVGU2g",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "from scipy.spatial.distance import cosine as dist",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VAJ0o2zVGU2j",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "enc = learn_lm.model[0].encoder",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-W7CQs56GU2m",
        "colab_type": "code",
        "outputId": "5a8cb3a8-8ad0-4e04-a271-7fbb5f0e4faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "enc.weight.size()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "heading_collapsed": true,
        "id": "6U5dmg8fGU2z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "### Difference in vocabulary between IMDB and Wikipedia"
    },
    {
      "metadata": {
        "hidden": true,
        "id": "tBuADx0DGU20",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "We are going to load wiki_itos, which can be downloaded along with wikitext-103.  We will compare the vocabulary from wikitext with the vocabulary in IMDB.  It is to be expected that the two sets have some different vocabulary words, and that is no problem for transfer learning!"
    },
    {
      "metadata": {
        "hidden": true,
        "id": "fCpcRFu7GU21",
        "colab_type": "code",
        "outputId": "94b05ca4-2191-476d-b049-96feea46b131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "len(wiki_itos)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "fL9v4BBwGU3H",
        "colab_type": "code",
        "outputId": "3d0bd3ee-d023-4838-d668-a217575e4d2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "len(vocab.itos)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "TSPjBlP5GU3K",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "i, unks = 0, []\nwhile len(unks) < 50:\n    if data_lm.vocab.itos[i] not in wiki_itos: unks.append((i,data_lm.vocab.itos[i]))\n    i += 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "VSxKheUEGU3N",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "wiki_words = set(wiki_itos)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "7w8g-4GPGU3Q",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "imdb_words = set(vocab.itos)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "33mo7Yz7GU3W",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "wiki_not_imbdb = wiki_words.difference(imdb_words)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "SvbH9DYbGU3i",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "imdb_not_wiki = imdb_words.difference(wiki_words)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "1NAOLWciGU3n",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "wiki_not_imdb_list = []\n\nfor i in range(100):\n    word = wiki_not_imbdb.pop()\n    wiki_not_imdb_list.append(word)\n    wiki_not_imbdb.add(word)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "f9zQU0OJGU3q",
        "colab_type": "code",
        "outputId": "398ffe5e-9848-4dfc-facc-bf692dace695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "wiki_not_imdb_list[:15]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "JkyTF3ZlGU3t",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "imdb_not_wiki_list = []\n\nfor i in range(100):\n    word = imdb_not_wiki.pop()\n    imdb_not_wiki_list.append(word)\n    imdb_not_wiki.add(word)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "PbWWmsGGGU3z",
        "colab_type": "code",
        "outputId": "2150e484-c8c5-48fb-c13d-ed2ea8b27ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "imdb_not_wiki_list[:15]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "wQ88GyHNGU32",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "All words that appear in the IMDB vocab, but not the wikitext-103 vocab, will be initialized to the same random vector in a model.  As the model trains, we will learn these weights."
    },
    {
      "metadata": {
        "hidden": true,
        "id": "-i29TbXcGU32",
        "colab_type": "code",
        "outputId": "f4f3d67c-a723-40b1-c695-8305bbe95629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "vocab.stoi[\"modernisation\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "O7QrMzf2GU35",
        "colab_type": "code",
        "outputId": "db575723-162f-4754-b2db-bc756941a3e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "\"modernisation\" in wiki_words",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "H0F7jTD5GU39",
        "colab_type": "code",
        "outputId": "55bee4c2-149b-4b5f-84d7-2d42c586d020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "vocab.stoi[\"30-something\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "Y9XZuOJDGU4A",
        "colab_type": "code",
        "outputId": "5b0502c9-f5de-48e9-f7c2-857a3f748a8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "\"30-something\" in wiki_words, \"30-something\" in imdb_words",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "bf3Bl1WpGU4H",
        "colab_type": "code",
        "outputId": "1955d835-99b1-4896-c055-88ec65bf5d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "vocab.stoi[\"linklater\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "4LVYH_SvGU4K",
        "colab_type": "code",
        "outputId": "1b8ce46b-fbbd-46e6-c0a5-84d8b502dac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "\"linklater\" in wiki_words, \"linklater\" in imdb_words",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "G0GoS04YGU4N",
        "colab_type": "code",
        "outputId": "cbbf19d9-7c0c-4e4b-c95d-8e5e52ae1886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "\"house\" in wiki_words, \"house\" in imdb_words",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "heading_collapsed": true,
        "id": "Jb33jakKGU4d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "### Generating fake movie reviews (using wiki-text model)"
    },
    {
      "metadata": {
        "id": "xsN5SGb32u4v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "### Generando comentarios falsos de películas (usando el modelo wiki-text)"
    },
    {
      "metadata": {
        "hidden": true,
        "id": "vNhmqd_YGU4h",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "TEXT = \"The color of the sky is\"\nN_WORDS = 40\nN_SENTENCES = 2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "scrolled": false,
        "id": "3UW7GL4XGU4k",
        "colab_type": "code",
        "outputId": "b25a7cbc-e947-44dc-c031-0ca2c3dca280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "40H_xjrMGU4n",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "TEXT = \"I hated this movie\"\nN_WORDS = 30\nN_SENTENCES = 2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "YoYN8fxKGU4r",
        "colab_type": "code",
        "outputId": "43bcf7f3-e007-448d-c64e-2abc0e2e73ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "j_iOgy4JGU4x",
        "colab_type": "code",
        "outputId": "737f82ef-2b49-48ef-8435-de55a59ff3b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "aCxs-Hi7GU42",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Lowering `temperature` will make the texts less randomized."
    },
    {
      "metadata": {
        "id": "CTrAxx8V3J1Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Bajar la \"temperatura\" hará que los textos sean menos random."
    },
    {
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "5jCR0P_QGU43",
        "colab_type": "code",
        "outputId": "6760a11d-03d0-43e9-9d4d-edefc48c9f02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.10) for _ in range(N_SENTENCES)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "DOl_BLynGU4-",
        "colab_type": "code",
        "outputId": "257f2ff4-d4bb-4e7e-8249-3a78f8b79108",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.10) for _ in range(N_SENTENCES)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d2b7AMkqGU5B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "### Training the model"
    },
    {
      "metadata": {
        "id": "45eNF-WT3mUC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "### Entrenando el modelo"
    },
    {
      "metadata": {
        "id": "ca_-cSrtGU5D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Now, we want to choose a good learning rate."
    },
    {
      "metadata": {
        "id": "WmgoDhRx3sC8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Ahora, queremos elegir una buena tasa de aprendizaje."
    },
    {
      "metadata": {
        "id": "8IradxXdGU5E",
        "colab_type": "code",
        "outputId": "9b8184f2-30c9-4587-c4f2-eb5eb565a992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_lm.lr_find()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8KkcshbpGU5I",
        "colab_type": "code",
        "outputId": "76a6b963-366b-4c65-a7c9-4ce93cfe1d37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_lm.recorder.plot(skip_end=15)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0ePPAIU7GU5K",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "lr = 1e-2\nlr *= bs/48",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vaMpgKPvGU5M",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_lm.to_fp16();",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dViiA68qGU5P",
        "colab_type": "code",
        "outputId": "8e9c15be-f860-4628-b9f7-1584d8f11b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_lm.fit_one_cycle(1, lr*10, moms=(0.8,0.7))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E9ohzRcYGU5T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Since this is relatively slow to train, we will save our weights:"
    },
    {
      "metadata": {
        "id": "505THeHs4ANu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Dado que esto es relativamente lento para entrenar, guardaremos nuestros pesos:"
    },
    {
      "metadata": {
        "id": "5sa4lWdYGU5U",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_lm.save('fit_1')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KoUcfLMDGU5X",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_lm.load('fit_1');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BQhsht8lGU5b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "To complete the fine-tuning, we can then unfreeze and launch a new training."
    },
    {
      "metadata": {
        "id": "TvI6GRuy4Opt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Para completar el ajuste, podemos descongelar y lanzar un nuevo entrenamiento."
    },
    {
      "metadata": {
        "id": "MQcvZSwZGU5f",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_lm.unfreeze()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "Mxsi7wI8GU5h",
        "colab_type": "code",
        "outputId": "7b6f05a4-1349-4da0-e914-6b2c5667deca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_lm.fit_one_cycle(10, lr, moms=(0.8,0.7))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "whCEjUDtGU5k",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_lm.save('fine_tuned')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hjSe77OeGU5n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "We have to save not just the model but also it's encoder, the part that's responsible for creating and updating the hidden state. For the next part, we don't care about the part that tries to guess the next word."
    },
    {
      "metadata": {
        "id": "6deUAxOW5Dod",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Tenemos que guardar no solo el modelo sino también su codificador, la parte responsable de crear y actualizar el estado oculto. Para la siguiente parte, no nos importa la parte que intenta adivinar la siguiente palabra."
    },
    {
      "metadata": {
        "id": "idVHLvUJGU5n",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_lm.save_encoder('fine_tuned_enc')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "heading_collapsed": true,
        "id": "pRMqZJH_GU5v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "### Loading our saved weights"
    },
    {
      "metadata": {
        "id": "V4n-wKII5ekw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "### Cargando nuestros pesos guardados"
    },
    {
      "metadata": {
        "hidden": true,
        "id": "pk4qDwp1GU5w",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_lm.load('fine_tuned');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "tbmH7dfwGU5z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Now that we've trained our model, different representations have been learned for the words that were in IMDB but not wiki (remember that at the beginning we had initialized them all to the same thing):"
    },
    {
      "metadata": {
        "id": "6V6Qcsfl5RRT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Ahora que hemos entrenado nuestro modelo, se han aprendido diferentes representaciones para las palabras que estaban en IMDB pero no en wiki (recuerde que al principio las habíamos inicializado todas a la misma cosa):"
    },
    {
      "metadata": {
        "hidden": true,
        "id": "ihudHy4NGU50",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "enc = learn_lm.model[0].encoder",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "lPSQ4YwxGU58",
        "colab_type": "code",
        "outputId": "e9221b0a-f412-4fae-830c-8ebaac75a6f4",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "np.allclose(enc.weight[vocab.stoi[\"30-something\"], :], \n            enc.weight[vocab.stoi[\"linklater\"], :])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "CM-HXslHGU59",
        "colab_type": "code",
        "outputId": "1157adb9-5cb9-4424-8470-2289252fe79b",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "np.allclose(enc.weight[vocab.stoi[\"30-something\"], :], new_word_vec)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q9pO_rMO5uBM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "### More generated movie reviews"
    },
    {
      "metadata": {
        "heading_collapsed": true,
        "id": "BfetLH28GU6E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "### Más comentarios de películas generadas"
    },
    {
      "metadata": {
        "hidden": true,
        "id": "sd0kmbAJGU6G",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "TEXT = \"i liked this movie because\"\nN_WORDS = 40\nN_SENTENCES = 2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "DMN9u-ciGU6I",
        "colab_type": "code",
        "outputId": "84f7e8ff-1684-49db-e31b-5fa74098321f",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "7c7pP3N_GU6P",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "TEXT = \"This movie was\"\nN_WORDS = 30\nN_SENTENCES = 2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "j-KArlh-GU6R",
        "colab_type": "code",
        "outputId": "9b69738a-94d4-4296-ba0c-f29f5c348e5a",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "fafjt0jqGU6W",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "TEXT = \"I hated this movie\"\nN_WORDS = 40\nN_SENTENCES = 2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "EkitKXq6GU6Y",
        "colab_type": "code",
        "outputId": "23e2da22-5522-418a-b0b9-0b4cf525702e",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9M6izB8vGU6c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "## Classifier"
    },
    {
      "metadata": {
        "id": "5TcXqQ8jGU6c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Now, we'll create a new data object that only grabs the labelled data and keeps those labels. Again, this line takes a bit of time."
    },
    {
      "metadata": {
        "id": "E1KtR4aj6OWM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Ahora, crearemos un nuevo objeto de datos que solo tome los datos etiquetados y conserve esas etiquetas. Nuevamente, esta línea lleva un poco de tiempo."
    },
    {
      "metadata": {
        "id": "ODusThuzGU6d",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "bs=48",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QZQbOH6YGU6e",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_clas = (TextList.from_folder(path, vocab=data_lm.vocab)\n             #grab all the text files in path\n             .split_by_folder(valid='test')\n             #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n             .label_from_folder(classes=['neg', 'pos'])\n             #label them all with their folders\n             .databunch(bs=bs, num_workers=1))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JXE7_1J5GU6g",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_clas.save('imdb_textlist_class')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4v52TXN9GU6i",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_clas = load_data(path, 'imdb_textlist_class', bs=bs, num_workers=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gcMC9SgeGU6k",
        "colab_type": "code",
        "outputId": "feb48d3a-6d8a-4876-e9af-7362f01019e8",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_clas.show_batch()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U3PoRcDYGU6m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "We can then create a model to classify those reviews and load the encoder we saved before."
    },
    {
      "metadata": {
        "id": "Znwy6tY96ZmI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Luego podemos crear un modelo para clasificar esas revisiones y cargar el codificador que guardamos antes."
    },
    {
      "metadata": {
        "id": "8Um8uAO-GU6n",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_c = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.3) #.to_fp16()\nlearn_c.load_encoder('fine_tuned_enc')\nlearn_c.freeze()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gbJK2vvRGU6p",
        "colab_type": "code",
        "outputId": "638cc12b-f633-42f3-d303-58fa8836be1b",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_c.lr_find()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-iGLhm7OGU6s",
        "colab_type": "code",
        "outputId": "44af9454-e319-4c34-f560-0335877cce0f",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_c.recorder.plot()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "XF41DKQlGU6w",
        "colab_type": "code",
        "outputId": "06b9d27c-d54f-4042-dcbf-c9feecfa8bc7",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_c.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zcqdv0MZGU6y",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_c.save('first')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u2_gtH5sGU60",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_c.load('first');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fhWHCc7wGU62",
        "colab_type": "code",
        "outputId": "7ec02f05-1be4-4de8-b142-5e635cef6ff9",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_c.freeze_to(-2)\nlearn_c.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ILrvY-foGU64",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_c.save('2nd')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X8sdfUd4GU67",
        "colab_type": "code",
        "outputId": "6157d744-40c3-4fcb-bd9e-66353885eee8",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_c.freeze_to(-3)\nlearn_c.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BM76SYGWGU6-",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_c.save('3rd')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wRchcEwYGU7B",
        "colab_type": "code",
        "outputId": "dcd86c4a-f198-4990-b5fd-51862fafd428",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_c.unfreeze()\nlearn_c.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jwWktBTxGU7C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "The state of the art for this dataset in 2017 was 94.1%."
    },
    {
      "metadata": {
        "id": "OKwDfbK46lIT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "El estado del arte para este conjunto de datos en 2017 fue del 94,1%."
    },
    {
      "metadata": {
        "id": "DxSB1HA_GU7D",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_c.save('clas')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k3lesNNbGU7F",
        "colab_type": "code",
        "outputId": "e44f6474-f004-4c12-d1a9-bc37e7da4160",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_c.predict(\"I really loved that movie, it was awesome!\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S79u50yDGU7H",
        "colab_type": "code",
        "outputId": "cd84e104-6329-4ced-9896-d06dba517089",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_c.predict(\"I didn't really love that movie, and I didn't think it was awesome.\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "IOAk3bu8GU7L",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "display_name": "Python 3.6 - AzureML",
      "language": "python"
    },
    "language_info": {
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "name": "python",
      "mimetype": "text/x-python",
      "version": "3.6.8",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "name": "5-nn-imdb.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 1
}